---
layout: post
title: KVM_EPT 源码分析
date: 2022-03-20
tags: jekyll
---

## 简介

从 CPU 角度看，物理机的内存是从一段地址 0 开始的可用物理内存。同样，在虚拟化中，也要为每个虚拟机提供这么一段从 0 开始，连续并且独占的物理地址。所以，虚拟化层需要为虚拟机模拟出这样一段内存空间，并进行管理。

在物理机上，CPU 对内存的访问是在保护模式下通过分段分页实现，在该模式下，CPU 访问的是虚拟地址。通过硬件 MMU 的转换后，才能将虚拟地址转换为物理地址，访问实际的物理内存。

在虚拟化场景下，虚拟机内存的 guest OS 也有自己的保护模式，所以当虚拟 CPU 进行内存访问时，使用的是虚拟机内部的虚拟地址，经过转换后，得到虚拟机物理地址。然后将物理地址转换为 qemu 进程的物理机地址，才能访问到内存数据。这就是 MMU 的虚拟化。

翻译步骤如下：

1. guest OS virtual address -> guest OS physical address：由虚拟机内核维护页表翻译，当发生缺页时，会触发内核缺页处理流程，并设置 GVA -> GPA 对应关系。
2. guest OS physical address -> host OS physical address：intel CPU 为内存虚拟化设计的扩展页表 (EPT) 功能。

EPT 使用 IA-32e 分页模式，使用 48 位物理地址，分为四级页表，每级使用 9 位物理地址，最后 12 位表示在一个页 (4KiB) 内的偏移。

## 内存注册接口

### qemu 侧

在 qemu 需要添加或删除内存 region 时，会向 KVM 注册/解注册内存槽。这一过程通过调用 kvm_set_user_memory_region 函数完成，内部通过系统调用，将 qemu 内存信息 slot index，gpa，hva，size，flag 等信息传递给 KVM。

```c
accel\kvm\kvm-all.c
kvm_set_user_memory_region
	mem.slot = slot->slot | (kml->as_id << 16);
    mem.guest_phys_addr = slot->start_addr;
    mem.userspace_addr = (unsigned long)slot->ram;
    mem.flags = slot->flags;
    mem.memory_size = slot->memory_size;
    kvm_vm_ioctl(s, KVM_SET_USER_MEMORY_REGION, &mem);
```

1. 上述的 slot 作为 KVM 内存槽的位置，从 0 号开始，每次增加 1
2. guest_phys_addr 来自虚拟机内存布局信息，只有 RAM 和 ROM 类型的内存才能向 KVM 注册
3. flags 设置对这段内存的是否只读，是否开启脏页跟踪等信息
4. memory_size 表示这段内存的长度
5. userspace_addr 表示 物理机的虚拟地址。在启动阶段，会调用 mmap 函数，从物理内存映射一段虚拟地址空间。这时并没有实际占用物理内存，只有在对内存进行读写时，才会真正从主机内核分配内存。

qemu 内存初始化过程中，会调用 ram_block_add 函数，添加新的 RAM block。由于时新建 RAM，所以 host 地址为空，通过 qemu_anon_ram_alloc 函数 mmap 分配内存，并储存到 new_block->host

```c
softmmu\physmem.c
ram_block_add
	if (!new_block->host) {
		new_block->host = qemu_anon_ram_alloc()
	}
```

现在，需要向 kvm 注册内存槽的所有数据都准备好了。

### KVM 侧

上述内容描述了 qemu 已经准备好内存信息，并且通过系统调用，向 kvm 内存槽注册这些信息。

在 kvm中，通过 kvm_userspace_memory_region 结构体表示一个内存槽

```c
include\uapi\linux\kvm.h
/* for KVM_SET_USER_MEMORY_REGION */
struct kvm_userspace_memory_region {
	__u32 slot;
	__u32 flags;
	__u64 guest_phys_addr;
	__u64 memory_size; 		/* bytes */
	__u64 userspace_addr; 	/* start of the userspace allocated memory */
};
```

系统调用的函数如下：

```c
virt\kvm\kvm_main.c
kvm_vm_ioctl_set_memory_region
	kvm_set_memory_region()
		__kvm_set_memory_region()
			// 检查 flags 信息，只支持 readonly 和 dirty log 两种 flag
			check_memory_region_flags(mem)
			// 校验内存地址对其和内存大小
			if (mem->memory_size & (PAGE_SIZE - 1))
				goto out;
			if (mem->guest_phys_addr & (PAGE_SIZE - 1))
				goto out;
				
			// 将 id 转换为 slot 的 ID 索引
			slot = id_to_memslot(__kvm_memslots(kvm, as_id), id)
			kvm_for_each_memslot(slot, __kvm_memslots(kvm, as_id)) {
				if (slot->id == id)
					continue;
				if (!((base_gfn + npages <= slot->base_gfn) ||
			      (base_gfn >= slot->base_gfn + slot->npages)))
					goto out;
			}
			
			// 如果是创建操作，kvm_arch_memory_slot 结构体，并进行初始化
			if (change == KVM_MR_CREATE) {
				kvm_arch_create_memslot(kvm, &new, npages)
			}
			
			// 把从 qemu 获取的值复制进去
			slots = kvzalloc(sizeof(struct kvm_memslots), GFP_KERNEL);
			memcpy(slots, __kvm_memslots(kvm, as_id), sizeof(struct kvm_memslots));
			
			// 更新并提交内存槽
			update_memslots(slots, &new);
			kvm_arch_commit_memory_region(kvm, mem, &old, &new, change)
```

这里以创建 mem slot 为例，首先会遍历内存槽，查看是否与当前内存槽有重合。接着调用 kvm_arch_create_memslot 函数，初始化内存槽的 arch。接着对 kvm_memslots 的 slots 进行赋值。最后将新添加的内存槽进行更新。

## 虚拟化 MMU

### MMU 翻译流程

在 EPT 机制下，虚拟机的内存方位都会触发一系列 GVA 到 GPA，GPA 到 HPA 的转换。EPT页表的基址保存在 VMCS 结构中的 EPTP 指针。

如果 GPA 到 HPA 的映射关系已经建立，即 EPT 页表已经保存了这一信息，那只需要通过 EPT 硬件辅助，就可以找到物理地址数据，不需要从虚拟机陷出到物理机。但是，如果在虚拟机内部发生缺页异常，即没有 GPA 到 HPA 的映射关系，则会产生 EPT 异常退出，虚拟机会退出到 KVM。由 KVM 构建对应的 EPT 页表，在后续访问时，无需再次退出，可以直接访问到物理数据。

### 虚拟 MMU 初始化

**支持 EPT**

VMCS 中 VM execution 区域的 secondary processr-based VM-execution control 字段的第二位用来表示是否开启 EPT。

![HK000710.png](https://gitee.com/orangehaswing/blog_images/raw/master/images/EPT/HK000710.png)

在 kvm 初始化过程中，会调用架构相关的 hardware_setup 函数。内部会调用 setup_vmcs_config，读取 MSR_IA32_VMX_PROCBASED_CTLS2，将寄存器存放在 vmcs_conf->cpu_base_2nd_exec_ctrl 中。

```c
arch\x86\kvm\vmx.c
setup_vmcs_config
	...
	if (adjust_vmx_controls(min2, opt2, MSR_IA32_VMX_PROCBASED_CTLS2, &_cpu_based_2nd_exec_control) < 0)
	...
	
adjust_vmx_controls
	rdmsr(msr, vmx_msr_low, vmx_msr_high);
	*result = ctl;
```

 **支持四级页表**

msr 寄存器 MSR_IA32_VMX_EPT_VPID_CAP 的第 6 位，表示支持四级页表。在调用 setup_vmcs_config 函数时，会将该信息保存在 vmx_capability.vpid 中。

```c
setup_vmcs_config
	rdmsr_safe(MSR_IA32_VMX_EPT_VPID_CAP, &vmx_capability.ept, &vmx_capability.vpid);
```

**开启 EPT**

在 kvm 初始化时，调用 hardware_setup，会设置 enable_ept 变量，默认值为 1。

```c
hardware_setup
	// 如果不满足下列的条件，不开启 EPT
	if (!cpu_has_vmx_ept() ||
	    !cpu_has_vmx_ept_4levels() ||
	    !cpu_has_vmx_ept_mt_wb() ||
	    !cpu_has_vmx_invept_global())
		enable_ept = 0;
	// 如果支持 ept，开启两级页表转换 (two dimentional paging)
	if (enable_ept)
		vmx_enable_tdp();
```

**创建 MMU**

在 kvm 初始化 vCPU时，会创建虚拟机 MMU，具体内容在 kvm_arch_vcpu_init 中调用 kvm_mmu_create

```c
kvm_vcpu_init()
	kvm_arch_vcpu_init()
		kvm_mmu_create()
		
arch\x86\kvm\mmu.c
kvm_mmu_create
	// 设置 arch 结构体
	vcpu->arch.walk_mmu = &vcpu->arch.mmu;
	vcpu->arch.mmu.root_hpa = INVALID_PAGE;
	vcpu->arch.mmu.translate_gpa = translate_gpa;
	
	return alloc_mmu_pages(vcpu);
```

最后的 alloc_mmu_pages 函数分配一个 pae 页，只在影子页表有实际作用。

在创建 vCPU 后，会在初始化阶段调用 kvm_mmu_setup 函数进行 MMU 的初始化

```c
arch\x86\kvm\mmu.c
kvm_mmu_setup
	kvm_init_mmu(vcpu, false)
		else if (tdp_enabled) {
			init_kvm_tdp_mmu(vcpu);
		}
```

这里判断标记位 tdp_enabled 开启，就初始化 tdp mmu。标记位 tdp_enabled 由上述的 hardware_setup -> vmx_enable_tdp 过程设置

初始化 tdp mmu 函数，就是初始化 kvm_vcpu_arch 结构体的 kvm_mmu 结构体。kvm_mmu 的作用时模拟 CPU 的 MMU 硬件。

```c
arch\x86\kvm\mmu.c
init_kvm_tdp_mmu
	struct kvm_mmu *context = &vcpu->arch.mmu;
	context->page_fault = tdp_page_fault;
	context->direct_map = true;
	...
```

最重要的函数是 tdp_page_fault，将在下文 EPT 页表构建中详细分析。root_hpa 表示指向 EPT 页表第一级页表的物理地址，类似 CR3 寄存器。direct_map 表示使用 EPT 直接映射。同时，还会设置 gva_to_gpa 等回调函数。

## EPT 页表构建

当虚拟机内部对内存访问时，MMU 首先将 GVA 转换为 GPA，然后根据 EPT 页表将 GPA 转换为 HPA，这就是 tdp，两级页表转换。但是，如果没有 GPA 对应的 HPA，这时候将发生缺页异常。这个异常会造成虚拟机发生退出，并且退出原因为EXIT_REASON_EPT_VIOLATION，对应的处理函数是 handle_ept_violation。

产生 EPT violation 的原因如下：

```
28.3.3.2 EPT Violations

	An EPT violation may occur during an access using a guest-physical address whose translation does not cause an EPT misconfiguration. An EPT violation occurs in any of the following situations:
	
	• Translation of the guest-physical address encounters an EPT paging-structure entry that is not present 
	• The access is a data read and, for any byte to be read, bit 0 (read access) was clear in any of the EPT paging structure entries used to translate the guest-physical address of the byte. Reads by the logical processor of guest paging structures to translate a linear address are considered to be data reads.
	• The access is a data write and, for any byte to be written, bit 1 (write access) was clear in any of the EPT paging-structure entries used to translate the guest-physical address of the byte. Writes by the logical processor to guest paging structures to update accessed and dirty flags are considered to be data writes.
	• The access is an instruction fetch and the EPT paging structures prevent execute access to any of the bytes being fetched.
	...
```

handle_ept_violation 函数内部会调用 page_fault 回调函数。由上文的 MMU 初始化过程可知，回调函数为 tdp_page_fault。

```c
arch\x86\kvm\vmx.c
vmx_handle_exit()
	// 获取退出原因
	exit_reason = vmx->exit_reason
	return kvm_vmx_exit_handlers[exit_reason](vcpu)
```

exit_reason 对应的 index 为 EXIT_REASON_EPT_VIOLATION，查询 kvm_vmx_exit_handlers 结构，回调函数为 handle_ept_violation

```c
arch\x86\kvm\vmx.c
handle_ept_violation
	// 从 vmcs 获取退出信息和虚拟机访问的 gpa
	exit_qualification = vmcs_readl(EXIT_QUALIFICATION)
	gpa = vmcs_read64(GUEST_PHYSICAL_ADDRESS)
	
	// 从 exit_qualification 获取读或写引起的 page fault 错误码，page table entry present 信息
	error_code = (exit_qualification & EPT_VIOLATION_ACC_READ) ? PFERR_USER_MASK : 0;
	...
	
	// 并把退出信息放在 vcpu arch
	vcpu->arch.exit_qualification = exit_qualification
	
	kvm_mmu_page_fault(vcpu, gpa, error_code, NULL, 0)
```

kvm_mmu_page_fault 函数调用 page_fault 回调函数 tdp_page_fault，也是 EPT 缺页处理的核心函数。

```c
arch\x86\kvm\mmu.c
kvm_mmu_page_fault
	vcpu->arch.mmu.page_fault

arch\x86\kvm\mmu.c
tdp_page_fault()
	// 分配缓存池的页表
	mmu_topup_memory_caches()
	
	// 处理大页情况，如果没用大页，level = 1
	force_pt_level = check_hugepage_cache_consistency()
	level = mapping_level(vcpu, gfn, &force_pt_level)
	
	// 对 page fault 快速处理，只有当 EPT 页表存在，并且是由写保护产生
	fast_page_fault()
	
	// 尝试对页进行一步处理，内部分配一个物理页，建立 hva->hpa 关系
	try_async_pf()
	
	// 建立 gpa->hpa 的映射
	__direct_map()
```

1. mmu_topup_memory_caches 函数负责分配缓冲区的内存空间，保证每次 EPT 获取 kernel page 都能成功。

2. check_hugepage_cache_consistency 函数负责对大页处理，mapping_level 函数根据2M或1G大页，获取mmaping level

   ```c
   mapping_level()
   	host_level = host_mapping_level(vcpu, large_gfn)
   		# 从 gfn 获取page size，从最小PT_PAGE_TABLE_LEVEL开始比较，直到PT_MAX_HUGEPAGE_LEVEL
   		page_size = kvm_host_page_size(vcpu, gfn)
   		
   		for (i = PT_PAGE_TABLE_LEVEL; i <= PT_MAX_HUGEPAGE_LEVEL; ++i) {
   			if (page_size >= KVM_HPAGE_SIZE(i))
   				ret = i;
   			else
   				break;
   	}
   ```

3. fast_page_fault 函数判断对页错误能否快速处理

4. try_async_pf 函数负责从 hva 分配一个物理页，在主机 MMU建立 hva -> hpa 的对应关系

   ```c
   arch\x86\kvm\mmu.c
   try_async_pf()
       # 从 kvm slots 和 gfn 获取对应内存槽
       slot = kvm_vcpu_gfn_to_memslot(vcpu, gfn)
       # 由gfn slot 获取 pfn
       *pfn = __gfn_to_pfn_memslot(slot, gfn, false, &async, write, writable)
       
   virt\kvm\kvm_main.c
   __gfn_to_pfn_memslot
       # 拿到 hva 地址
   	addr = __gfn_to_hva_many(slot, gfn, NULL, write_fault)
       
       # 在 MMIO 分支，返回 KVM_PFN_NOSLOT
       if (kvm_is_error_hva(addr)) {
           return KVM_PFN_NOSLOT;
       }
   
   	# 从 hva 转换 pfn，利用了主机 MMU 功能
   	return hva_to_pfn(addr, atomic, async, write_fault, writable)
   ```

上述最关键的函数是 __direct_map，填充 EPT 页表。

```c
__direct_map
	for_each_shadow_entry(vcpu, gpa, it) {
		// 如果找到对应 page level，跳出循环
		if (it.level == level)
			break;
		// 逐级判断 4 级页表是否存在
		if (!is_shadow_present_pte(*it.sptep)) {
			// 不存在，分配一个 MMU kernel page
			sp = kvm_mmu_get_page()
			// 将当前目录项指向分配的页表
			link_shadow_page()
		}
	}
	
	// 将最后一级页表的页表项指向物理页面(user page)
	mmu_set_spte()
```

## MMIO 机制

在启动阶段，qemu 会为设备分配 MMIO 内存空间对应的基址，一般为 4 MiB。这部分内存会作为 virtio 设备的bar空间，存放设备寄存器等信息。

当虚拟机第一次访问 MMIO 地址空间时，会发生 EPT violation，虚拟机退出到主机。KVM 在收到 EPT violation 退出原因后，按上述的 page fault 流程，创建一个 EPT 页表。但是 MMIO 地址空间的内容由 qemu 管理，所以会为页表设置特殊的标志，可写可执行，但不可读。

当虚拟机再次访问对应的 MMIO 地址空间，发现是不可读，但是可写，可执行，会产生 EPT misconfig，从而产生 VM Exit，退出到 KVM。由KVM 负责分发事件到 qemu 侧。

MMIO 产生 EPT misconfig 的原因如下：

```
28.3.3.1 EPT Misconfigurations

	An EPT misconfiguration occurs if translation of a guest-physical address encounters an EPT paging-structure entry that meets any of the following conditions:
	
	• Bit 0 of the entry is clear (indicating that data reads are not allowed) and any of the following hold:
		— Bit 1 is set (indicating that data writes are allowed).
		— The processor does not support execute-only translations and either of the following hold:
			• Bit 2 is set (indicating that instruction fetches are allowed).
			• The “mode-based execute control for EPT” VM-execution control is 1 and bit 10 is set (indicating that instruction fetches are allowed from user-mode linear addresses).
		Software should read the VMX capability MSR IA32_VMX_EPT_VPID_CAP to determine whether execute-only translations are supported.
		— The “EPT paging-write control” VM-execution control is 1, the entry maps a page, and bit 58 is set 
(indicating that paging writes are allowed).

	• The entry is present and of the following holds:
		— A reserved bit is set. This includes the setting of a bit in the range 51:12 that is beyond the logical processor’s physical-address width. for details of which bits are reserved in which EPT paging-structure entries.
		— The entry is the last one used to translate a guest physical address (either an EPT PDE with bit 7 set to 1 or an EPT PTE) and the value of bits 5:3 (EPT memory type) is 2, 3, or 7 (these values are reserved).
```

**标记 MMIO mask**

在 vmx_init 初始化时，会调用 ept_set_mmio_spte_mark 函数，设置全局的 mmio_mask 标记。

```c
arch\x86\kvm\vmx.c
hardware_setup()
	vmx_enable_tdp()
		ept_set_mmio_spte_mask()
			kvm_mmu_set_mmio_spte_mask(VMX_EPT_RWX_MASK, VMX_EPT_MISCONFIG_WX_VALUE)
				shadow_mmio_value = mmio_value | SPTE_SPECIAL_MASK;
				shadow_mmio_mask = mmio_mask | SPTE_SPECIAL_MASK;
```

这里，在 enbale tdp 过程中，设置了全局变量 shadow_mmio_value 和 shadow_mmio_mask。

**第一次陷出：EPT violation**

当调用 tdp_page_fault 处理 EPT 页表时，会调用 try_async_pf 函数，由 hva 分配对应的物理页，分配 hpa。

由 qemu 侧注册内存过程可知，只有 RAM 和 ROM 类型内存才会调系统调用 kvm_set_user_memory_region 函数，注册memory slot  内存槽信息。MMIO 地址空间，不会调用 kvm_set_user_memory_region 函数，所以 gpa 对应的 gfn，在 try_async_pf 函数找不到 pfn，返回标记 KVM_PFN_NOSLOT。接着调用 __direct_map 构建页表。为 MMIO 对应的页表属性添加 shadow_mmio_mask。

```c
arch\x86\kvm\mmu.c
tdp_page_fault()
	// 尝试分配物理页面，结果失败，返回 KVM_PFN_NOSLOT
	try_async_pf()
	
	// EPT 页表映射
	__direct_map()
		mmu_set_spte()
			set_spte()
				// 设置 EPT mmio 属性
				set_mmio_spte()
					// 校验标志 KVM_PFN_NOSLOT
					if (unlikely(is_noslot_pfn(pfn))){
						mark_mmio_spte
							access &= ACC_WRITE_MASK | ACC_USER_MASK;
							mask |= shadow_mmio_value | access;
							mmu_spte_set()
					}
					
```

这样，MMIO 对应的 EPT 页表属性就添加到了 mask，为 110b。显然，该页表对应的页为可写，可执行，但是不可读，是一个矛盾的配置项，当虚拟机再次访问时，会产生 EPT misconfig 类型的 VM Exit。

**第二次陷出：EPT misconfig**

如上述设置的 EPT 标记位，再次访问 MMIO 地址时，对应 kvm_vmx_exit_handlers 数组的 handle_ept_misconfig 函数

```c
arch\x86\kvm\vmx.c
handle_ept_misconfig()
	// 从 vmcs 获取 gpa 信息
	gpa = vmcs_read64(GUEST_PHYSICAL_ADDRESS)
	// 如果不能由 kvm 处理，例如不是中断相关 mmio
	if (!kvm_io_bus_write(vcpu, KVM_FAST_MMIO_BUS, gpa, 0, NULL)) {
		// 设置需要模拟该指令
		kvm_emulate_instruction()
	}
	
	// 处理 mmu page fault
	kvm_mmu_page_fault()
```

在 kvm_mmu_page_fault 函数，会直接调用 handle_mmio_page_fault 函数，进行校验和标记，让其退出到 qemu 处理

```c
arch\x86\kvm\mmu.c
kvm_mmu_page_fault()
	if (unlikely(error_code & PFERR_RSVD_MASK)) {
		handle_mmio_page_fault()
			// 访问的 MMIO 地址在缓存，可以快速返回
			if (mmio_info_in_cache(vcpu, addr, direct))
				return RET_PF_EMULATE;
			// 得到 gpa 地址对应的 spte
			walk_shadow_page_get_mmio_spte(vcpu, addr, &spte)
			
			// 如果是 mmio spte
			if (is_mmio_spte(spte)) {
				// 获取 gfn 和 access
				gfn = get_mmio_spte_gfn(spte)
				access = get_mmio_spte_access(spte)
				
				// 校验 mmio spte
				check_mmio_spte(vcpu, spte)
				
				// 向 vcpu 缓存 mmio，方便下次快速返回
				vcpu_cache_mmio_info(vcpu, addr, gfn, access);
				
				// 返回指令模拟
				return RET_PF_EMULATE;
			}
	}
	
	emulate:
		// 根据上述指令模拟，写eventfd，目的是让qemu epoll到对应virtio设备事件，并且设置 er
		er = x86_emulate_instruction()
		
		// 需要退出到用户态
		case EMULATE_USER_EXIT:
			++vcpu->stat.mmio_exits;
```
